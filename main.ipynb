{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Getting Top 20 List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to aggregate the list of players who have been on every year's HLTV Top 20. The entire process is not computationally laborious, so the resulting DataFrame was not saved locally.\n",
    "\n",
    "The function **_getTop20(year, index)_** accepts a certain year as well as the dictionary of indices to each list's webpage on hltv.com. A couple of exceptions had to be made because it appeared that HLTV changed their HTML webpages between the years 2017 and 2018. This resulted in the player extraction for years 2018 and 2019 to be harder. The function returns an array that has the player names in order from #1 to #20.\n",
    "\n",
    "The function **_aggregateTop20()_** serves as the main function that uses the helper function **_getTop20_**. I went to each year's introduction page and took down the index numbers, which were unique. Luckily, the rest of the url were the same across all four, making iteration easy. Since **_getTop20_** returns a 20x1 numpy array, the **_aggregateTop20_** makes a 20x4 numpy array. This numpy array was then converted and returned as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTop20(year, index):\n",
    "    url = 'https://www.hltv.org/news/' + str(index) + '/top-20-players-of-' + str(year) + '-introduction'\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "    arr = np.array([])\n",
    "    \n",
    "    if year in [2016, 2017]:\n",
    "        for i in soup.find_all('tr'):\n",
    "            arr = np.concatenate((arr,[i.text.split()[2][1:-1]]))\n",
    "    elif year in [2018, 2019]:\n",
    "        top20 = soup.find_all('blockquote')[1].text.strip()\n",
    "        top20list = re.compile(\"[0-9]+\\.  \").split(top20)\n",
    "        for player in top20list:\n",
    "            if not len(player) <= 1:\n",
    "                arr = np.concatenate((arr,[player.split('\"')[1]]))\n",
    "    else:\n",
    "        print('Error')\n",
    "    return arr\n",
    "\n",
    "\n",
    "def aggregateTop20():  \n",
    "    top20indices = {2016: 19558, 2017: 22348, 2018: 25735, 2019: 28749}\n",
    "\n",
    "    top20 = np.array([])\n",
    "    for year in top20indices:\n",
    "        top20 = np.concatenate((top20,getTop20(year, top20indices[year]))) \n",
    "        time.sleep(1)\n",
    "    df = pd.DataFrame(top20.reshape(4,20).swapaxes(0,1), columns=list(top20indices.keys()))\n",
    "    df.index = np.arange(1,21)\n",
    "    return df\n",
    "\n",
    "top20DF = aggregateTop20()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Scraping: Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, data scraping begins with finding individual statistics for all the players in a given year. These features will also be saved locally. Later, filtering will reduce the amount of players used in the machine learning model. The purpose of this section is to just save **all** players locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Unfiltered Players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, the player names from each year must be collected from HLTV's repo. Since HLTV did not publish advanced statistics until late 2015, only the years 2016, 2017, 2018, 2019 are used. \n",
    "\n",
    "Only LAN matches are counted, while no filter restriction is placed on the Player Filter. The **_oneYear(year)_** function is a helper function that returns a string that has the date range depending on the year supplied. Each year has its own HTML file, and the collection of all four HTML files are placed in the 'unfilteredplayers' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneYear(year):\n",
    "    return 'startDate=' + str(year) + '-01-01&endDate=' + str(year) + '-12-31'\n",
    "\n",
    "for year in np.arange(2016,2020):\n",
    "    url = 'https://www.hltv.org/stats/players?' + oneYear(year) + '&matchType=Lan'\n",
    "    temp = requests.get(url).text\n",
    "    with open('unfilteredplayers/players' + str(year) + '.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(temp)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These html files now must be read and turned into .csv files. The **_allplayersonLAN(year)_** function below takes in a year and reads that year's HTML page that has the list of players who have official statistics on LAN events only. A dictionary is returned that maps players' names to players' individual statistic page based on the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allplayersonLAN(year):\n",
    "    with open('unfilteredplayers/players' + str(year) + '.html','r',encoding='utf-8') as players_html:\n",
    "        soup = BeautifulSoup(players_html,'lxml')\n",
    "    temp = {}\n",
    "    for player in soup.find_all('td',class_='playerCol'):\n",
    "        temp[player.text] = 'https://hltv.org' + player.find('a')['href']\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **_htmlToCsvUnfiltered(year)_** function is the main function that transforms the HTML files into CSV files. It uses **_allplayersonLAN_** as a helper function to produce a dictionary, which is then converted to a DataFrame and then exported as a .csv. These .csv files are then placed in 'unfilteredplayers' as well, accompanying the .html files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-Number of unfiltered players: 190\n",
      "2017-Number of unfiltered players: 284\n",
      "2018-Number of unfiltered players: 252\n",
      "2019-Number of unfiltered players: 234\n"
     ]
    }
   ],
   "source": [
    "def htmlToCsvUnfiltered(year): \n",
    "    playerlist = allplayersonLAN(year)\n",
    "    tab = pd.DataFrame.from_dict(playerlist,orient='index',columns=['Webpage'])\n",
    "    tab.to_csv('unfilteredplayers/players' + str(year) + '.csv')\n",
    "    print(str(year) + \"-Number of unfiltered players: \" + str(len(playerlist)))\n",
    "    return\n",
    "\n",
    "for year in np.arange(2016,2020):\n",
    "    htmlToCsvUnfiltered(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Did a player make HLTV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Section 2, **_aggregateTop20()_** produced a DataFrame of all the Top 20 lists for the four years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>coldzera</td>\n",
       "      <td>coldzera</td>\n",
       "      <td>s1mple</td>\n",
       "      <td>ZywOo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FalleN</td>\n",
       "      <td>NiKo</td>\n",
       "      <td>device</td>\n",
       "      <td>s1mple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>device</td>\n",
       "      <td>fer</td>\n",
       "      <td>NiKo</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>s1mple</td>\n",
       "      <td>rain</td>\n",
       "      <td>electronic</td>\n",
       "      <td>EliGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Snax</td>\n",
       "      <td>device</td>\n",
       "      <td>dupreeh</td>\n",
       "      <td>Magisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>shox</td>\n",
       "      <td>FalleN</td>\n",
       "      <td>NAF</td>\n",
       "      <td>electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>f0rest</td>\n",
       "      <td>kennyS</td>\n",
       "      <td>Magisk</td>\n",
       "      <td>NAF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>olofmeister</td>\n",
       "      <td>s1mple</td>\n",
       "      <td>gla1ve</td>\n",
       "      <td>Brehze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>ScreaM</td>\n",
       "      <td>GuardiaN</td>\n",
       "      <td>KRIMZ</td>\n",
       "      <td>Twistzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>flusha</td>\n",
       "      <td>dupreeh</td>\n",
       "      <td>coldzera</td>\n",
       "      <td>ropz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>NiKo</td>\n",
       "      <td>Hobbit</td>\n",
       "      <td>GuardiaN</td>\n",
       "      <td>NiKo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>flamie</td>\n",
       "      <td>EliGE</td>\n",
       "      <td>Twistzz</td>\n",
       "      <td>woxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>kennyS</td>\n",
       "      <td>Xyp9x</td>\n",
       "      <td>Xyp9x</td>\n",
       "      <td>sergej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Magiskb0Y</td>\n",
       "      <td>k0nfig</td>\n",
       "      <td>oskar</td>\n",
       "      <td>Xyp9x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>fer</td>\n",
       "      <td>Kjaerbye</td>\n",
       "      <td>EliGE</td>\n",
       "      <td>jks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Kjaerbye</td>\n",
       "      <td>oskar</td>\n",
       "      <td>suNny</td>\n",
       "      <td>dupreeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>GuardiaN</td>\n",
       "      <td>AdreN</td>\n",
       "      <td>autimatic</td>\n",
       "      <td>KRIMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>GeT_RiGhT</td>\n",
       "      <td>boltz</td>\n",
       "      <td>rain</td>\n",
       "      <td>CeRq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>fnx</td>\n",
       "      <td>olofmeister</td>\n",
       "      <td>ropz</td>\n",
       "      <td>Brollan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>dennis</td>\n",
       "      <td>Snax</td>\n",
       "      <td>valde</td>\n",
       "      <td>Ethan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2016         2017        2018        2019\n",
       "1      coldzera     coldzera      s1mple       ZywOo\n",
       "2        FalleN         NiKo      device      s1mple\n",
       "3        device          fer        NiKo      device\n",
       "4        s1mple         rain  electronic       EliGE\n",
       "5          Snax       device     dupreeh      Magisk\n",
       "6          shox       FalleN         NAF  electronic\n",
       "7        f0rest       kennyS      Magisk         NAF\n",
       "8   olofmeister       s1mple      gla1ve      Brehze\n",
       "9        ScreaM     GuardiaN       KRIMZ     Twistzz\n",
       "10       flusha      dupreeh    coldzera        ropz\n",
       "11         NiKo       Hobbit    GuardiaN        NiKo\n",
       "12       flamie        EliGE     Twistzz       woxic\n",
       "13       kennyS        Xyp9x       Xyp9x      sergej\n",
       "14    Magiskb0Y       k0nfig       oskar       Xyp9x\n",
       "15          fer     Kjaerbye       EliGE         jks\n",
       "16     Kjaerbye        oskar       suNny     dupreeh\n",
       "17     GuardiaN        AdreN   autimatic       KRIMZ\n",
       "18    GeT_RiGhT        boltz        rain        CeRq\n",
       "19          fnx  olofmeister        ropz     Brollan\n",
       "20       dennis         Snax       valde       Ethan"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_checkIfTop20(row,top20)_** is a function that is to be applied across a DataFrame of all the players. It takes in a DataFrame row as well as a Series that contains the Top 20 based on the provided year. An example is shown below with the players from 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage</th>\n",
       "      <th>HLTV Top 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Jamppi</td>\n",
       "      <td>https://hltv.org/stats/players/14087/Jamppi?st...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZywOo</td>\n",
       "      <td>https://hltv.org/stats/players/11893/ZywOo?sta...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s1mple</td>\n",
       "      <td>https://hltv.org/stats/players/7998/s1mple?sta...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>witz</td>\n",
       "      <td>https://hltv.org/stats/players/13995/witz?star...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Papichulo</td>\n",
       "      <td>https://hltv.org/stats/players/15440/Papichulo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>daps</td>\n",
       "      <td>https://hltv.org/stats/players/8521/daps?start...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tiziaN</td>\n",
       "      <td>https://hltv.org/stats/players/5796/tiziaN?sta...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HUNDEN</td>\n",
       "      <td>https://hltv.org/stats/players/7415/HUNDEN?sta...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>advent</td>\n",
       "      <td>https://hltv.org/stats/players/8600/advent?sta...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gob b</td>\n",
       "      <td>https://hltv.org/stats/players/136/gob%20b?sta...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Webpage  HLTV Top 20\n",
       "Jamppi     https://hltv.org/stats/players/14087/Jamppi?st...        False\n",
       "ZywOo      https://hltv.org/stats/players/11893/ZywOo?sta...         True\n",
       "s1mple     https://hltv.org/stats/players/7998/s1mple?sta...         True\n",
       "witz       https://hltv.org/stats/players/13995/witz?star...        False\n",
       "Papichulo  https://hltv.org/stats/players/15440/Papichulo...        False\n",
       "...                                                      ...          ...\n",
       "daps       https://hltv.org/stats/players/8521/daps?start...        False\n",
       "tiziaN     https://hltv.org/stats/players/5796/tiziaN?sta...        False\n",
       "HUNDEN     https://hltv.org/stats/players/7415/HUNDEN?sta...        False\n",
       "advent     https://hltv.org/stats/players/8600/advent?sta...        False\n",
       "gob b      https://hltv.org/stats/players/136/gob%20b?sta...        False\n",
       "\n",
       "[234 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkIfTop20(row,top20):\n",
    "    name = row.name\n",
    "    if top20.str.contains(name,regex=False).sum() > 0:\n",
    "        return True\n",
    "    else:    \n",
    "        return False\n",
    "\n",
    "df = pd.read_csv('unfilteredplayers/players2019.csv',index_col=0)\n",
    "df.insert(df.shape[1],'HLTV Top 20',df.apply(checkIfTop20,axis=1,args=(top20DF.loc[:,2019],)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction is based on the three tabs of a player: Overview, Individual, and Matches. A total of 12 statistics will be used as features:\n",
    "\n",
    "- Rating (0)\n",
    "- ADR (1)\n",
    "- KPR (2)\n",
    "- DPR (3)\n",
    "- APR (4)\n",
    "- IMPACT (5)\n",
    "- KAST (6)\n",
    "- Grenade dmg (7)\n",
    "- k-d diff (8)\n",
    "- Opening kill ratio (9)\n",
    "- team win percent after 1st kill (10)\n",
    "- % of maps with 1+ rating (11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_getScaledRating(sp)_** is a helper function that scales player rating based on the player's rating against top 5, 10, 20, 30, and 50 opponents. **_getFromOverview(url,arr)_** is the main function that fills in a stats array with the statistics that can be taken from the player's overview page. \n",
    "\n",
    "- Rating (0)\n",
    "- ADR (1)\n",
    "- KPR (2)\n",
    "- DPR (3)\n",
    "- APR (4)\n",
    "- IMPACT (5)\n",
    "- KAST (6)\n",
    "- Grenade dmg (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScaledRating(sp):\n",
    "    ratingsTab = sp.find('div',class_='featured-ratings-container')\n",
    "    scales = {'vs top 5 opponents': 0.4, 'vs top 10 opponents': 0.3, 'vs top 20 opponents': 0.2, \n",
    "              'vs top 30 opponents': 0.075, 'vs top 50 opponents': 0.025}\n",
    "    scaledrating = 0\n",
    "    for rating in ratingsTab.find_all('div',class_='rating-breakdown'):\n",
    "        val = 0\n",
    "        ratingtype = rating.find('div',class_='rating-description').text\n",
    "        mapcount = int(rating.find('div',class_='rating-maps').text[1:-1].split()[0])\n",
    "        if mapcount == 0:\n",
    "            continue \n",
    "        \n",
    "        temp = float(rating.find('div',class_='rating-value').text)\n",
    "        val = temp * scales[ratingtype]\n",
    "        \n",
    "        if ratingtype == 'vs top 5 opponents' and mapcount < 10:\n",
    "            val *= 0.75\n",
    "        elif ratingtype== 'vs top 10 opponents' and mapcount < 20:\n",
    "            val *= 0.75\n",
    "        elif ratingtype== 'vs top 20 opponents' and mapcount < 40:\n",
    "            val *= 0.75       \n",
    "        scaledrating += val\n",
    "\n",
    "    return scaledrating\n",
    "\n",
    "\n",
    "def getFromOverview(url, arr):\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "    statsIndex = {'Rating': 0, 'ADR': 1, 'KPR': 2, 'DPR': 3, \n",
    "                  'Assists / round': 4, 'Impact': 5, 'KAST': 6, 'Grenade dmg / Round': 7}\n",
    "    \n",
    "    # ADR, KPR, DPR, KAST, IMPACT\n",
    "    for i in soup.find_all('div',class_=re.compile('summaryStatBreakdown ')):\n",
    "        statname = i.find('div',class_='summaryStatBreakdownSubHeader').text.split()[0]\n",
    "        if statname in statsIndex:\n",
    "            if statname == 'KAST':\n",
    "                arr[statsIndex[statname]] = i.find('div',class_='summaryStatBreakdownDataValue').text[:-1]\n",
    "            else:\n",
    "                arr[statsIndex[statname]] = i.find('div',class_='summaryStatBreakdownDataValue').text\n",
    "    \n",
    "    # APR, Grenade Dmg/ Round\n",
    "    for i in soup.find_all('div',class_='stats-row'):\n",
    "        if i.text.find('Grenade dmg / Round') > -1:\n",
    "            arr[statsIndex['Grenade dmg / Round']] = i.find_all('span')[1].text\n",
    "        elif i.text.find('Assists / round') > -1:\n",
    "            arr[statsIndex['Assists / round']] = i.find_all('span')[1].text\n",
    "            \n",
    "    # Rating Scale\n",
    "    arr[statsIndex['Rating']] = getScaledRating(soup)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_getFromIndividual(url,arr)_** is the main function that fills in a stats array with the statistics that can be taken from the player's Individual page. \n",
    "\n",
    "- k-d diff (8)\n",
    "- Opening kill ratio (9)\n",
    "- team win percent after 1st kill (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFromIndividual(url, arr):\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "    statsIndex = {'Kill - Death difference': 8, 'Opening kill ratio': 9, 'Team win percent after first kill': 10}\n",
    "    for i in soup.find_all('div',class_='stats-row'):\n",
    "        statname = i.span.text\n",
    "        if statname in statsIndex:\n",
    "            if statname == 'Kill - Death difference':\n",
    "                arr[statsIndex[statname]] = i.span.next_sibling.next_sibling.text\n",
    "            elif statname == 'Team win percent after first kill':\n",
    "                arr[statsIndex[statname]] = i.span.next_sibling.text[:-1]\n",
    "            else:\n",
    "                arr[statsIndex[statname]] = i.span.next_sibling.text\n",
    "                \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_getFromMatches(url,arr)_** is the main function that fills in a stats array with the statistics that can be taken from the player's Matches page. \n",
    "\n",
    "- % of maps with 1+ rating (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFromMatches(url, arr):\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "    statsIndex = {'Maps with 1+ rating': 11}\n",
    "    for i in soup.find_all('div',class_='col'):\n",
    "        statname = i.find('div',class_='description').text\n",
    "        if statname is None:\n",
    "            continue\n",
    "        elif statname in statsIndex:\n",
    "            arr[statsIndex[statname]] = i.find('div',class_='value').text[:-1]\n",
    "            break\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_getFeatures(row)_** is applied across an entire DataFrame and uses the three functions defined above. It takes in a row and returns a numpy array that contains the statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(row):\n",
    "    statsarr = np.zeros((12,))\n",
    "    \n",
    "    overvUrl = row['Webpage']\n",
    "    statsarr = getFromOverview(overvUrl,statsarr)\n",
    "    time.sleep(7.5)\n",
    "    indivUrl = overvUrl[:31] + 'individual/' + overvUrl[31:]\n",
    "    statsarr = getFromIndividual(indivUrl,statsarr)\n",
    "    time.sleep(7.5)\n",
    "    matchUrl = overvUrl[:31] + 'matches/' + overvUrl[31:]\n",
    "    statsarr = getFromMatches(matchUrl,statsarr)\n",
    "    time.sleep(7.5)\n",
    "    return statsarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since applying **_getFeatures_** returns a Series of 12x1 numpy arrays, this nested structure needs to be flattened into a non-nested two-dimensional array. **_flattenFeatures(s,df)** extracts the nested structure made from the applied function and combines it with the existing DataFrame that came from the end of section 3-1. The Series is first converted into a numpy array, then numpy's **stack** function will flatten it. It is then concatenated with the original DataFrame that just had player names and hltv URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenFeatures(s,df):\n",
    "    flat = np.stack(s.to_numpy())\n",
    "   \n",
    "    featureNames = np.array(['Adj. Rating','ADR','KPR','DPR','APR',\n",
    "                         'Impact','KAST','NadePR','K-D Diff', \n",
    "                         'Opening Kill Ratio', 'Team win % after 1st kill', '% of maps with 1+ rating'])\n",
    "    features = pd.DataFrame(data=flat, columns=featureNames)\n",
    "    features.index = df.index\n",
    "    \n",
    "    final = pd.concat([df,features],axis=1)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since applying **_extractFinalFeature_** is the main function for feature extraction. It takes in a year as well as the top20DF created in section 2. It reads in the DataFrame saved in section 3-1 and then adds a column checking whether or not a player made it in that year's HLTV top 20. It will then call **_getFeatures_** to produce the Series of numpy arrays that contains all the stats. That series is inserted along with the DataFrame into **_flattenFeatures_** to produce a combined DataFrame with all the features necessary for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFinalFeatures(year):\n",
    "    top20DF = aggregateTop20()\n",
    "    df = pd.read_csv('unfilteredplayers/players' + str(year) + '.csv',index_col=0)\n",
    "    df.insert(df.shape[1],'HLTV Top 20',df.apply(checkIfTop20,axis=1,args=(top20DF.loc[:,year],)))\n",
    "    \n",
    "    statsonly = df.apply(getFeatures,axis=1)\n",
    "    \n",
    "    finalTab = flattenFeatures(statsonly,df)\n",
    "    \n",
    "    finalTab.to_csv('features/features'+str(year)+'.csv') \n",
    "    \n",
    "    return\n",
    "\n",
    "extractFinalFeatures(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Scraping: Filtering Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>XANTARES</td>\n",
       "      <td>https://hltv.org/stats/players/7938/XANTARES?s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZELIN</td>\n",
       "      <td>https://hltv.org/stats/players/9001/ZELIN?star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>coldzera</td>\n",
       "      <td>https://hltv.org/stats/players/9216/coldzera?s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oskar</td>\n",
       "      <td>https://hltv.org/stats/players/798/oskar?start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>device</td>\n",
       "      <td>https://hltv.org/stats/players/7592/device?sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B1ad3</td>\n",
       "      <td>https://hltv.org/stats/players/472/B1ad3?start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MSL</td>\n",
       "      <td>https://hltv.org/stats/players/7156/MSL?startD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nkl</td>\n",
       "      <td>https://hltv.org/stats/players/5327/nkl?startD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freakazoid</td>\n",
       "      <td>https://hltv.org/stats/players/7808/freakazoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pronax</td>\n",
       "      <td>https://hltv.org/stats/players/41/pronax?start...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Webpage\n",
       "XANTARES    https://hltv.org/stats/players/7938/XANTARES?s...\n",
       "ZELIN       https://hltv.org/stats/players/9001/ZELIN?star...\n",
       "coldzera    https://hltv.org/stats/players/9216/coldzera?s...\n",
       "oskar       https://hltv.org/stats/players/798/oskar?start...\n",
       "device      https://hltv.org/stats/players/7592/device?sta...\n",
       "...                                                       ...\n",
       "B1ad3       https://hltv.org/stats/players/472/B1ad3?start...\n",
       "MSL         https://hltv.org/stats/players/7156/MSL?startD...\n",
       "nkl         https://hltv.org/stats/players/5327/nkl?startD...\n",
       "freakazoid  https://hltv.org/stats/players/7808/freakazoid...\n",
       "pronax      https://hltv.org/stats/players/41/pronax?start...\n",
       "\n",
       "[190 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('unfilteredplayers/players2016.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **_allplayersonLAN(year)_** function below takes in a year and reads that year's HTML page that has the list of players who have official statistics on LAN events only. A dictionary is returned that maps players' names to players' individual statistic page based on the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allplayersonLAN(year):\n",
    "    with open('unfilteredplayers/players' + str(year) + '.html','r',encoding='utf-8') as players_html:\n",
    "        soup = BeautifulSoup(players_html,'lxml')\n",
    "    temp = {}\n",
    "    for player in soup.find_all('td',class_='playerCol'):\n",
    "        temp[player.text] = 'https://hltv.org' + player.find('a')['href']\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **_againstTop50(row)_** function checks if each player in the dictionary above has at least played 20 maps against rank top 50 opponents. It takes in a DataFrame row, and this function will be applied across the entire DataFrame using panda's **apply()** function. The return is boolean: true if player has played at least 20 maps against top 50 opponents, and false if player has not. \n",
    "\n",
    "This portion of the filtering process might be subject to change. 20 maps against top 50 opponents appears to be a very low bar to clear, might adjust later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def againstTop50(row):\n",
    "    name = row.name\n",
    "    url = row.Webpage\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "    for i in soup.find_all('div',class_='col-custom'):\n",
    "        if i.text.find('top 50 opponents') > -1:\n",
    "            mapsplayed = i.find('div',class_='rating-maps').text.split()[0].split('(')[1]\n",
    "            if int(mapsplayed) >= 20:\n",
    "                return True\n",
    "    time.sleep(7.5)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function combines the two above to filter out players that may have not participated in enough important events. A dictionary is formed using allplayersonLAN() and then converted into a DataFrame. The againstTop50 function is applied across every row of the DataFrame to produce a Series that says if each player has or has not played 20 maps against top 50 opponenets.\n",
    "\n",
    "- 2016-Number of unfiltered players: 190\n",
    "- 2016-Number of filtered players: 171\n",
    "- 2017-Number of unfiltered players: 284\n",
    "- 2017-Number of filtered players: 181\n",
    "- 2018-Number of unfiltered players: 252\n",
    "- 2018-Number of filtered players: 223\n",
    "- 2019-Number of unfiltered players: 234\n",
    "- 2019-Number of filtered players: 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-Number of unfiltered players: 190\n"
     ]
    }
   ],
   "source": [
    "def exportFilteredPlayers(year): \n",
    "    playerlist = allplayersonLAN(year)\n",
    "    tab = pd.DataFrame.from_dict(playerlist,orient='index',columns=['Webpage'])\n",
    "#    tab.insert(tab.shape[1],'AgainstTop50',tab.apply(againstTop50,axis=1))\n",
    "    tab.to_csv('filteredplayers/players' + str(year) + '.csv')\n",
    "    print(str(year) + \"-Number of unfiltered players: \" + str(len(playerlist)))\n",
    "  #  print(str(year) + \"-Number of filtered players: \" + str(tab[tab.AgainstTop50].shape[0]))\n",
    "    return\n",
    "\n",
    "#for year in np.arange(2016,2020):\n",
    "exportFilteredPlayers(2016)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
